# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/CLI_Index_File_Generator.ipynb.

# %% auto 0
__all__ = ['index_website_data']

# %% ../nbs/CLI_Index_File_Generator.ipynb 1
from typing import *

import typer
from llama_index.readers.schema.base import Document
from llama_index import download_loader, GPTSimpleVectorIndex

from ._helper import get_all_links_from_website, get_service_context, write_compressed_json, filter_out_old_doc_urls

# %% ../nbs/CLI_Index_File_Generator.ipynb 4
def _index_website_data(
    start_url: str = "https://fastkafka.airt.ai",
    data_dir: str = "./data",
) -> None:
    """Extract and index website data from the given start URL.

    Args:
        start_url: The starting URL of the website. Defaults to "https://fastkafka.airt.ai".
        data_dir: The data directory path to save the index file generated by parsing all the website links.
    """
    all_urls = list(get_all_links_from_website(start_url))
    current_docs_urls = filter_out_old_doc_urls(start_url, all_urls)
    
    typer.echo("\nIndexing the contents from the following URL's: \n")
    typer.echo("\n".join(sorted(current_docs_urls)))
    BeautifulSoupWebReader = download_loader("BeautifulSoupWebReader")
    loader = BeautifulSoupWebReader()
    documents = loader.load_data(urls=current_docs_urls)

    service_context = get_service_context()
    index = GPTSimpleVectorIndex.from_documents(
        documents, service_context=service_context
    )
    write_compressed_json(index.save_to_string(), f"{data_dir}/website_index.json")
    typer.echo("\nIndexing successfully completed.")

# %% ../nbs/CLI_Index_File_Generator.ipynb 6
_app = typer.Typer()


@_app.command(
    help="Recursively parses all anchor links found on the website and index website data from the given start URL",
)
def index_website_data(
    start_url: str = typer.Option(
        "https://fastkafka.airt.ai",
        help="The starting URL of the website",
    ),
    data_dir: str = typer.Option(
        "./data/",
        help="The data directory path to save the index file generated by parsing all the website links.",
    ),
) -> None:
    try:
        _index_website_data(
            start_url=start_url,
            data_dir=data_dir
        )
    except Exception as e:
        typer.secho(e, err=True, fg=typer.colors.RED)
        raise typer.Exit(1)
