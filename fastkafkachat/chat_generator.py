# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/Chat_Generator.ipynb.

# %% auto 0
__all__ = ['router', 'load_document_from_directory', 'GenerateChatRequest', 'generate_chat_response']

# %% ../nbs/Chat_Generator.ipynb 1
from pathlib import Path
from typing import *
from os import environ
import random
import logging
import time

from fastapi import APIRouter
from pydantic import BaseModel

from llama_index import GPTSimpleVectorIndex, SimpleDirectoryReader, LLMPredictor, ServiceContext
from llama_index.readers.schema.base import Document
from langchain.chat_models import ChatOpenAI


# %% ../nbs/Chat_Generator.ipynb 3
def load_document_from_directory(directory_path: str) -> List[Document]:
    documents = SimpleDirectoryReader(directory_path).load_data()
    return documents

# %% ../nbs/Chat_Generator.ipynb 5
def _get_response_from_model(user_query: str, root_path: str = ".") -> str:
    # LLM Predictor (gpt-3.5-turbo) + service context
    llm_predictor = LLMPredictor(
        llm=ChatOpenAI(temperature=0, model_name="gpt-3.5-turbo")
    )
    service_context = ServiceContext.from_defaults(
        llm_predictor=llm_predictor, chunk_size_limit=512
    )
    
    documents = load_document_from_directory(f"{root_path}/data/")
    index = GPTSimpleVectorIndex.from_documents(
        documents, service_context=service_context
    )
    response = index.query(
        user_query,
        service_context=service_context,
        similarity_top_k=3,
    )
    return response

# %% ../nbs/Chat_Generator.ipynb 7
router = APIRouter()


# %% ../nbs/Chat_Generator.ipynb 8
class GenerateChatRequest(BaseModel):
    user_query: str

# %% ../nbs/Chat_Generator.ipynb 9
@router.post("/")
def generate_chat_response(
    generate_chat_response_request: GenerateChatRequest,
) -> str:
    model_response = _get_response_from_model(generate_chat_response_request.user_query)
    return model_response.response
