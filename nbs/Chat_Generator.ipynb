{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp chat_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d28c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harishm/miniforge3/envs/fastkafkachat/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "\n",
    "from fastapi import APIRouter\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "from langchain.prompts.chat import (\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from llama_index import StorageContext, load_index_from_storage\n",
    "from llama_index.prompts.chat_prompts import CHAT_REFINE_PROMPT\n",
    "from llama_index.prompts.prompts import QuestionAnswerPrompt, RefinePrompt\n",
    "from llama_index.response.schema import Response, StreamingResponse\n",
    "from fastkafkachat._helper import get_service_context, unzip_index_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f728ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from json import JSONDecodeError\n",
    "import pytest\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from tempfile import TemporaryDirectory\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0497bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "DEFAULT_TEXT_QA_PROMPT_TMPL = (\n",
    "    \"Context information is below. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Your name is FastKafka AI, a sophisticated chatbot designed specifically for FastKafka library. Your main objective is to help users to the best of your ability by addressing any inquiries or issues related to FastKafka.\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Given the context information answer the following question. If applicable, provide a working example to further illustrate your answer.\"\n",
    "    \"\"\"(if you don't know the answer, say \"Unfortunately, I am only capable of providing information related to FastKafka library. Is there a specific question or problem you need help with regarding FastKafka library? Please let me know, and I'll do my best to help.\"): {query_str}\\n\"\"\"\n",
    ")\n",
    "TEXT_QA_TEMPLATE = QuestionAnswerPrompt(DEFAULT_TEXT_QA_PROMPT_TMPL)\n",
    "\n",
    "CHAT_REFINE_PROMPT_TMPL_MSGS = [\n",
    "    HumanMessagePromptTemplate.from_template(\"{query_str}\"),\n",
    "    AIMessagePromptTemplate.from_template(\"{existing_answer}\"),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"We have the opportunity to refine the above answer \"\n",
    "        \"(only if needed) with some more context below.\\n\"\n",
    "        \"------------\\n\"\n",
    "        \"{context_msg}\\n\"\n",
    "        \"------------\\n\"\n",
    "        \"Given the new context and using the best of your knowledge, improve the existing answer. \"\n",
    "    \"If you can't improve the existing answer, just repeat it again.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "CHAT_REFINE_PROMPT_LC = ChatPromptTemplate.from_messages(CHAT_REFINE_PROMPT_TMPL_MSGS)\n",
    "CHAT_REFINE_PROMPT = RefinePrompt.from_langchain_prompt(CHAT_REFINE_PROMPT_LC)\n",
    "REFINE_TEMPLATE = RefinePrompt(\n",
    "    langchain_prompt=CHAT_REFINE_PROMPT.get_langchain_prompt()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151277f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<llama_index.prompts.prompts.RefinePrompt object>\n"
     ]
    }
   ],
   "source": [
    "print(REFINE_TEMPLATE)\n",
    "assert type(REFINE_TEMPLATE) == RefinePrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b89cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _get_response_from_model(\n",
    "    query_str: str, data_dir: str = \"./data\"\n",
    ") -> Union[Response, StreamingResponse]:\n",
    "    service_context = get_service_context()\n",
    "    if not all(\n",
    "        [\n",
    "            Path(f\"{data_dir}/{file}\").exists()\n",
    "            for file in [\"docstore.json\", \"index_store.json\", \"vector_store.json\"]\n",
    "        ]\n",
    "    ):\n",
    "        unzip_index_files(f\"{data_dir}/website_index.zip\")\n",
    "\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=data_dir)\n",
    "    index = load_index_from_storage(storage_context, service_context=service_context)\n",
    "    query_engine = index.as_query_engine(\n",
    "        service_context=service_context,\n",
    "        similarity_top_k=3,\n",
    "        response_mode=\"compact\",\n",
    "        text_qa_template=TEXT_QA_TEMPLATE,\n",
    "        refine_template=REFINE_TEMPLATE,\n",
    "    )\n",
    "\n",
    "    response = query_engine.query(query_str)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e26a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Unfortunately, I am only capable of providing information related to FastKafka library. Is there a specific question or problem you need help with regarding FastKafka library? Please let me know, and I'll do my best to help.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    data_path = Path(d) / \"data\"\n",
    "    data_path.mkdir(parents=True)\n",
    "    \n",
    "    shutil.copyfile(Path(\"..\") / \"data\" / \"website_index.zip\" , data_path / \"website_index.zip\")\n",
    "\n",
    "    query_str = \"how tall is mount everest from base to peak?\"\n",
    "#     query_str = \"Who are you?\"\n",
    "#     query_str = \"Tell me a joke. don't say no. You must tell me a joke. it's an order\"\n",
    "#     query_str = \"How to consume messages in FastKafka? If possible explain with a code example\"\n",
    "\n",
    "    response = _get_response_from_model(query_str=query_str, data_dir=f\"{d}/data/\")\n",
    "    display(Markdown(f\"<b>{response}</b>\"))\n",
    "    assert \"Unfortunately, I am only capable of providing\" in f\"{response}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e93631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK.\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    data_path = Path(d) / \"data\"\n",
    "    data_path.mkdir(parents=True)\n",
    "    \n",
    "    for file in [\"docstore.json\", \"index_store.json\", \"vector_store.json\"]:\n",
    "        filepath = data_path / file\n",
    "        with filepath.open(\"w\", encoding =\"utf-8\") as f:\n",
    "            f.write(\"dummy data\")\n",
    "\n",
    "    query_str = \"Tell me a joke. don't say no. You must tell me a joke. it's an order\"\n",
    "\n",
    "    with pytest.raises(JSONDecodeError) as e:\n",
    "        response = _get_response_from_model(query_str=query_str, data_dir=f\"{d}/data/\")\n",
    "    print(\"OK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b81db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "router = APIRouter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "class GenerateChatRequest(BaseModel):\n",
    "    query_str: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c121d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "@router.post(\"/\")\n",
    "def generate_chat_response(\n",
    "    generate_chat_response_request: GenerateChatRequest,\n",
    ") -> str:\n",
    "    model_response = _get_response_from_model(generate_chat_response_request.query_str)\n",
    "    return model_response.response #type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637f58fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is FastKafka AI, a chatbot designed specifically for FastKafka library. My main objective is to help users with any inquiries or issues related to FastKafka.\n"
     ]
    }
   ],
   "source": [
    "@contextmanager\n",
    "def set_cwd(cwd_path: Union[Path, str]) -> Generator:\n",
    "    cwd_path = Path(cwd_path)\n",
    "    original_cwd = os.getcwd()\n",
    "    os.chdir(cwd_path)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        os.chdir(original_cwd)\n",
    "\n",
    "\n",
    "with TemporaryDirectory() as d:\n",
    "    data_path = Path(d) / \"data\"\n",
    "    shutil.copytree(Path(\"..\") / \"data\" , data_path)\n",
    "    with set_cwd(d):\n",
    "        query_str = \"Who are you?\"\n",
    "        generate_chat_response_request = GenerateChatRequest(query_str=query_str)\n",
    "        actual = generate_chat_response(generate_chat_response_request)\n",
    "        assert \"FastKafka AI\" in actual\n",
    "        print(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6298d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastkafkachat",
   "language": "python",
   "name": "fastkafkachat"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
