{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp chat_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d28c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# | export\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "from os import environ\n",
    "import random\n",
    "import logging\n",
    "import time\n",
    "\n",
    "from fastapi import APIRouter\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from llama_index import GPTSimpleVectorIndex, SimpleDirectoryReader, LLMPredictor, ServiceContext\n",
    "from llama_index.readers.schema.base import Document\n",
    "from langchain.chat_models import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f728ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from contextlib import contextmanager\n",
    "import unittest.mock\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "\n",
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d8ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def load_document_from_directory(directory_path: str) -> List[Document]:\n",
    "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a19a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(text='@consumes basics¤\\nYou can use @consumes decorator to consume messages from Kafka topics.\\n\\nIn this guide we will create a simple FastKafka app that will consume HelloWorld messages from hello_world topic.\\n\\nImport FastKafka¤\\nTo use the @consumes decorator, first we need to import the base FastKafka app to create our application.\\n\\n\\nfrom fastkafka import FastKafka\\nDefine the structure of the messages¤\\nNext, you need to define the structure of the messages you want to consume from the topic using pydantic. For the guide we’ll stick to something basic, but you are free to define any complex message structure you wish in your project, just make sure it can be JSON encoded.\\n\\nLet’s import BaseModel and Field from pydantic and create a simple HelloWorld class containing one string parameter msg\\n\\n\\nfrom pydantic import BaseModel, Field\\n\\nclass HelloWorld(BaseModel):\\n    msg: str = Field(\\n        ...,\\n        example=\"Hello\",\\n        description=\"Demo hello world message\",\\n    )\\nCreate a base FastKafka app¤\\nNow we will create and define a base FastKafka app, replace the <url_of_your_kafka_bootstrap_server> and <port_of_your_kafka_bootstrap_server> with the actual values of your Kafka bootstrap server\\n\\n\\nkafka_brokers = {\\n    \"demo_broker\": {\\n        \"url\": \"<url_of_your_kafka_bootstrap_server>\",\\n        \"description\": \"local demo kafka broker\",\\n        \"port\": \"<port_of_your_kafka_bootstrap_server>\",\\n    }\\n}\\n\\napp = FastKafka(kafka_brokers=kafka_brokers)\\nCreate a consumer function and decorate it with @consumes¤\\nLet’s create a consumer function that will consume HelloWorld messages from hello_world topic and log them.\\n\\n\\nfrom fastkafka._components.logger import get_logger\\n\\nlogger = get_logger(__name__)\\n\\n@app.consumes()\\nasync def on_hello_world(msg: HelloWorld):\\n    logger.info(f\"Got msg: {msg}\")\\nThe function decorated with the @consumes decorator will be called when a message is produced to Kafka.\\n\\nThe message will then be injected into the typed msg argument of the function and its type will be used to parse the message.\\n\\nIn this example case, when the message is sent into a hello_world topic, it will be parsed into a HelloWorld class and on_hello_world function will be called with the parsed class as msg argument value.\\n\\nFinal app¤\\nYour app code should look like this:\\n\\n\\nfrom fastkafka import FastKafka\\nfrom pydantic import BaseModel, Field\\n\\nclass HelloWorld(BaseModel):\\n    msg: str = Field(\\n        ...,\\n        example=\"Hello\",\\n        description=\"Demo hello world message\",\\n    )\\n\\n\\nkafka_brokers = {\\n    \"demo_broker\": {\\n        \"url\": \"<url_of_your_kafka_bootstrap_server>\",\\n        \"description\": \"local demo kafka broker\",\\n        \"port\": \"<port_of_your_kafka_bootstrap_server>\",\\n    }\\n}\\n\\napp = FastKafka(kafka_brokers=kafka_brokers)\\n\\nfrom fastkafka._components.logger import get_logger\\n\\nlogger = get_logger(__name__)\\n\\n@app.consumes()\\nasync def on_hello_world(msg: HelloWorld):\\n    logger.info(f\"Got msg: {msg}\")\\nRun the app¤\\nNow we can run the app. Copy the code above in consumer_example.py and run it by running\\n\\n\\nfastkafka run --num-workers=1 --kafka-broker=demo_broker consumer_example:app\\nAfter running the command, you should see this output in your terminal:\\n\\n\\n[382372]: [INFO] fastkafka._application.app: set_kafka_broker() : Setting bootstrap_servers value to \\'127.0.0.1:9092\\'\\n[382372]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\\n[382372]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {\\'bootstrap_servers\\': \\'127.0.0.1:9092\\', \\'auto_offset_reset\\': \\'earliest\\', \\'max_poll_records\\': 100}\\n[382372]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\\n[382372]: [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({\\'hello_world\\'})\\n[382372]: [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {\\'hello_world\\'}\\n[382372]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\\n[382372]: [WARNING] aiokafka.cluster: Topic hello_world is not available during auto-create initialization\\n[382372]: [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {\\'hello_world\\': 0}. \\nStarting process cleanup, this may take a few seconds...\\n[INFO] fastkafka._server: terminate_asyncio_process(): Terminating the process 382372...\\n[382372]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\\n[382372]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\\n[INFO] fastkafka._server: terminate_asyncio_process(): Process 382372 terminated.\\n\\nSend the message to kafka topic¤\\nLets send a HelloWorld message to the hello_world topic and check if our consumer kafka application has logged the received message. In your terminal, run:\\n\\n\\necho {\\\\\"msg\\\\\": \\\\\"Hello world\\\\\"} | kafka-console-producer.sh --topic=hello_world --bootstrap-server=<addr_of_your_kafka_bootstrap_server>\\nYou should see the “Got msg: msg=\\'Hello world\\'” being logged by your consumer.\\n\\nChoosing a topic¤\\nYou probably noticed that you didn’t define which topic you are receiving the message from, this is because the @consumes decorator determines the topic by default from your function name. The decorator will take your function name and strip the default “on_” prefix from it and use the rest as the topic name. In this example case, the topic is hello_world.\\n\\nYou can choose your custom prefix by defining the prefix parameter in consumes decorator, like this:\\n\\n\\nfrom fastkafka._components.logger import get_logger\\n\\nlogger = get_logger(__name__)\\n\\n@app.consumes(prefix=\"read_from_\")\\nasync def read_from_hello_world(msg: HelloWorld):\\n    logger.info(f\"Got msg: {msg}\")\\nAlso, you can define the topic name completely by defining the topic in parameter in consumes decorator, like this:\\n\\n\\nfrom fastkafka._components.logger import get_logger\\n\\nlogger = get_logger(__name__)\\n\\n@app.consumes(topic=\"my_special_topic\")\\nasync def on_hello_world(msg: HelloWorld):\\n    logger.info(f\"Got msg: {msg}\")\\nMessage data¤\\nThe message received from kafka is translated from binary JSON representation int the class defined by typing of msg parameter in the function decorated by the @consumes decorator.\\n\\nIn this example case, the message will be parsed into a HelloWorld class.', doc_id='9bc33561-0107-44c1-b618-5473c80c6dc5', embedding=None, doc_hash='4a87a51f879d0d615aa6649bd81ae7947085e6b74a5ca662a9a8abb2c17b51ff', extra_info=None)]\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    data_path = Path(d) / \"data\"\n",
    "    data_path.mkdir(parents=True)\n",
    "    \n",
    "    shutil.copyfile(\n",
    "        Path(\"..\") / \"data\" / \"data.txt\", data_path / \"data.txt\"\n",
    "    )\n",
    "    \n",
    "    documents = load_document_from_directory(str(data_path))\n",
    "    print(documents)\n",
    "#     index = GPTSimpleVectorIndex.from_documents(documents)\n",
    "#     response = index.query(\"What is Fastkafka?\")\n",
    "#     print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b89cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _get_response_from_model(user_query: str, root_path: str = \".\") -> str:\n",
    "    # LLM Predictor (gpt-3.5-turbo) + service context\n",
    "    llm_predictor = LLMPredictor(\n",
    "        llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "    )\n",
    "    service_context = ServiceContext.from_defaults(\n",
    "        llm_predictor=llm_predictor, chunk_size_limit=512\n",
    "    )\n",
    "    \n",
    "    documents = load_document_from_directory(f\"{root_path}/data/\")\n",
    "    index = GPTSimpleVectorIndex.from_documents(\n",
    "        documents, service_context=service_context\n",
    "    )\n",
    "    response = index.query(\n",
    "        user_query,\n",
    "        service_context=service_context,\n",
    "        similarity_top_k=3,\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e26a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:llama_index.llm_predictor.base:Unknown max input size for gpt-3.5-turbo, using defaults.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(text='@consumes basics¤\\nYou can use @consumes decorator to consume messages from Kafka topics.\\n\\nIn this guide we will create a simple FastKafka app that will consume HelloWorld messages from hello_world topic.\\n\\nImport FastKafka¤\\nTo use the @consumes decorator, first we need to import the base FastKafka app to create our application.\\n\\n\\nfrom fastkafka import FastKafka\\nDefine the structure of the messages¤\\nNext, you need to define the structure of the messages you want to consume from the topic using pydantic. For the guide we’ll stick to something basic, but you are free to define any complex message structure you wish in your project, just make sure it can be JSON encoded.\\n\\nLet’s import BaseModel and Field from pydantic and create a simple HelloWorld class containing one string parameter msg\\n\\n\\nfrom pydantic import BaseModel, Field\\n\\nclass HelloWorld(BaseModel):\\n    msg: str = Field(\\n        ...,\\n        example=\"Hello\",\\n        description=\"Demo hello world message\",\\n    )\\nCreate a base FastKafka app¤\\nNow we will create and define a base FastKafka app, replace the <url_of_your_kafka_bootstrap_server> and <port_of_your_kafka_bootstrap_server> with the actual values of your Kafka bootstrap server\\n\\n\\nkafka_brokers = {\\n    \"demo_broker\": {\\n        \"url\": \"<url_of_your_kafka_bootstrap_server>\",\\n        \"description\": \"local demo kafka broker\",\\n        \"port\": \"<port_of_your_kafka_bootstrap_server>\",\\n    }\\n}\\n\\napp = FastKafka(kafka_brokers=kafka_brokers)\\nCreate a consumer function and decorate it with @consumes¤\\nLet’s create a consumer function that will consume HelloWorld messages from hello_world topic and log them.\\n\\n\\nfrom fastkafka._components.logger import get_logger\\n\\nlogger = get_logger(__name__)\\n\\n@app.consumes()\\nasync def on_hello_world(msg: HelloWorld):\\n    logger.info(f\"Got msg: {msg}\")\\nThe function decorated with the @consumes decorator will be called when a message is produced to Kafka.\\n\\nThe message will then be injected into the typed msg argument of the function and its type will be used to parse the message.\\n\\nIn this example case, when the message is sent into a hello_world topic, it will be parsed into a HelloWorld class and on_hello_world function will be called with the parsed class as msg argument value.\\n\\nFinal app¤\\nYour app code should look like this:\\n\\n\\nfrom fastkafka import FastKafka\\nfrom pydantic import BaseModel, Field\\n\\nclass HelloWorld(BaseModel):\\n    msg: str = Field(\\n        ...,\\n        example=\"Hello\",\\n        description=\"Demo hello world message\",\\n    )\\n\\n\\nkafka_brokers = {\\n    \"demo_broker\": {\\n        \"url\": \"<url_of_your_kafka_bootstrap_server>\",\\n        \"description\": \"local demo kafka broker\",\\n        \"port\": \"<port_of_your_kafka_bootstrap_server>\",\\n    }\\n}\\n\\napp = FastKafka(kafka_brokers=kafka_brokers)\\n\\nfrom fastkafka._components.logger import get_logger\\n\\nlogger = get_logger(__name__)\\n\\n@app.consumes()\\nasync def on_hello_world(msg: HelloWorld):\\n    logger.info(f\"Got msg: {msg}\")\\nRun the app¤\\nNow we can run the app. Copy the code above in consumer_example.py and run it by running\\n\\n\\nfastkafka run --num-workers=1 --kafka-broker=demo_broker consumer_example:app\\nAfter running the command, you should see this output in your terminal:\\n\\n\\n[382372]: [INFO] fastkafka._application.app: set_kafka_broker() : Setting bootstrap_servers value to \\'127.0.0.1:9092\\'\\n[382372]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\\n[382372]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {\\'bootstrap_servers\\': \\'127.0.0.1:9092\\', \\'auto_offset_reset\\': \\'earliest\\', \\'max_poll_records\\': 100}\\n[382372]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\\n[382372]: [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({\\'hello_world\\'})\\n[382372]: [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {\\'hello_world\\'}\\n[382372]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\\n[382372]: [WARNING] aiokafka.cluster: Topic hello_world is not available during auto-create initialization\\n[382372]: [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {\\'hello_world\\': 0}. \\nStarting process cleanup, this may take a few seconds...\\n[INFO] fastkafka._server: terminate_asyncio_process(): Terminating the process 382372...\\n[382372]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\\n[382372]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\\n[INFO] fastkafka._server: terminate_asyncio_process(): Process 382372 terminated.\\n\\nSend the message to kafka topic¤\\nLets send a HelloWorld message to the hello_world topic and check if our consumer kafka application has logged the received message. In your terminal, run:\\n\\n\\necho {\\\\\"msg\\\\\": \\\\\"Hello world\\\\\"} | kafka-console-producer.sh --topic=hello_world --bootstrap-server=<addr_of_your_kafka_bootstrap_server>\\nYou should see the “Got msg: msg=\\'Hello world\\'” being logged by your consumer.\\n\\nChoosing a topic¤\\nYou probably noticed that you didn’t define which topic you are receiving the message from, this is because the @consumes decorator determines the topic by default from your function name. The decorator will take your function name and strip the default “on_” prefix from it and use the rest as the topic name. In this example case, the topic is hello_world.\\n\\nYou can choose your custom prefix by defining the prefix parameter in consumes decorator, like this:\\n\\n\\nfrom fastkafka._components.logger import get_logger\\n\\nlogger = get_logger(__name__)\\n\\n@app.consumes(prefix=\"read_from_\")\\nasync def read_from_hello_world(msg: HelloWorld):\\n    logger.info(f\"Got msg: {msg}\")\\nAlso, you can define the topic name completely by defining the topic in parameter in consumes decorator, like this:\\n\\n\\nfrom fastkafka._components.logger import get_logger\\n\\nlogger = get_logger(__name__)\\n\\n@app.consumes(topic=\"my_special_topic\")\\nasync def on_hello_world(msg: HelloWorld):\\n    logger.info(f\"Got msg: {msg}\")\\nMessage data¤\\nThe message received from kafka is translated from binary JSON representation int the class defined by typing of msg parameter in the function decorated by the @consumes decorator.\\n\\nIn this example case, the message will be parsed into a HelloWorld class.', doc_id='a57054a4-b24d-485e-a488-71cb7ae58f0a', embedding=None, doc_hash='4a87a51f879d0d615aa6649bd81ae7947085e6b74a5ca662a9a8abb2c17b51ff', extra_info=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 3196 tokens\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 3398 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 14 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To consume FastKafka messages, you can use the @consumes decorator to define a function that consumes messages from a Kafka topic. For example, if you have a Kafka topic called \"hello_world\", you can consume messages from this topic using the following code:\n",
      "\n",
      "```\n",
      "from fastkafka import FastKafka\n",
      "from pydantic import BaseModel, Field\n",
      "\n",
      "class HelloWorld(BaseModel):\n",
      "    msg: str = Field(\n",
      "        ...,\n",
      "        example=\"Hello\",\n",
      "        description=\"Demo hello world message\",\n",
      "    )\n",
      "\n",
      "kafka_brokers = {\n",
      "    \"demo_broker\": {\n",
      "        \"url\": \"<url_of_your_kafka_bootstrap_server>\",\n",
      "        \"description\": \"local demo kafka broker\",\n",
      "        \"port\": \"<port_of_your_kafka_bootstrap_server>\",\n",
      "    }\n",
      "}\n",
      "\n",
      "app = FastKafka(kafka_brokers=kafka_brokers)\n",
      "\n",
      "from fastkafka._components.logger import get_logger\n",
      "logger = get_logger(__name__)\n",
      "\n",
      "@app.consumes()\n",
      "async def on_hello_world(msg: HelloWorld):\n",
      "    logger.info(f\"Got msg: {msg}\")\n",
      "\n",
      "```\n",
      "\n",
      "In this example, the `@consumes()` decorator defines the function `on_hello_world` as a consumer for messages from the Kafka topic `hello_world`. When a message is sent to the `hello_world` topic, it will be parsed into a `HelloWorld` class, and the `on_hello_world` function will be called with the parsed class as the `msg` argument value. The function will then log the received message.\n",
      "\n",
      "You can run the application with the following command:\n",
      "\n",
      "```\n",
      "fastkafka run --num-workers=1 --kafka-broker=demo_broker consumer_example:app\n",
      "```\n",
      "\n",
      "To send a message to the `hello_world` topic, you can use a command-line Kafka producer:\n",
      "\n",
      "```\n",
      "echo {\\\"msg\\\": \\\"Hello world\\\"} | kafka-console-producer.sh --topic=hello_world --bootstrap-server=<addr_of_your_kafka_bootstrap_server>\n",
      "```\n",
      "\n",
      "After running the command, the consumer application should log the received message. By default, the topic name is determined by the function name without the \"on_\" prefix. However, you can use the `prefix` parameter in the `@consumes` decorator to customize the topic prefix, or the `topic` parameter to specify a completely custom topic name.\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    data_path = Path(d) / \"data\"\n",
    "    data_path.mkdir(parents=True)\n",
    "    \n",
    "    shutil.copyfile(\n",
    "        Path(\"..\") / \"data\" / \"data.txt\", data_path / \"data.txt\"\n",
    "    )\n",
    "    user_query = \"How to consume Fastkafka messages? Give me an example?\"\n",
    "    response = _get_response_from_model(user_query=user_query, root_path=d)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b81db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "router = APIRouter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "class GenerateChatRequest(BaseModel):\n",
    "    user_query: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c121d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@router.post(\"/\")\n",
    "def generate_chat_response(\n",
    "    generate_chat_response_request: GenerateChatRequest,\n",
    ") -> str:\n",
    "    model_response = _get_response_from_model(generate_chat_response_request.user_query)\n",
    "    return model_response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637f58fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:llama_index.llm_predictor.base:Unknown max input size for gpt-3.5-turbo, using defaults.\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 14 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    data_path = Path(d) / \"data\"\n",
    "    data_path.mkdir(parents=True)\n",
    "    \n",
    "    shutil.copyfile(\n",
    "        Path(\"..\") / \"data\" / \"data.txt\", data_path / \"data.txt\"\n",
    "    )\n",
    "    user_query = \"How to consume Fastkafka messages? Give me an example?\"\n",
    "    generate_chat_response_request = GenerateChatRequest(\n",
    "        user_query=user_query, documents=documents\n",
    "    )\n",
    "    actual = generate_chat_response(generate_chat_response_request)\n",
    "    print(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6298d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastkafka-3.8",
   "language": "python",
   "name": "fastkafka-3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
