{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1105f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp chat_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806b729d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harishm/.pyenv/versions/3.10.4/lib/python3.10/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# | export\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "from os import environ\n",
    "import random\n",
    "import logging\n",
    "import time\n",
    "\n",
    "from fastapi import APIRouter\n",
    "from pydantic import BaseModel\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703d87a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "import unittest.mock\n",
    "\n",
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d333d0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "# Reference: https://github.com/openai/openai-cookbook/blob/main/examples/How_to_handle_rate_limits.ipynb\n",
    "\n",
    "\n",
    "def _retry_with_exponential_backoff(\n",
    "    initial_delay: float = 1,\n",
    "    exponential_base: float = 2,\n",
    "    jitter: bool = True,\n",
    "    max_retries: int = 10,\n",
    "    max_wait: float = 60,\n",
    "    errors: tuple = (\n",
    "        openai.error.RateLimitError,\n",
    "        openai.error.ServiceUnavailableError,\n",
    "        openai.error.APIError,\n",
    "    ),\n",
    ") -> Callable:\n",
    "    \"\"\"Retry a function with exponential backoff.\"\"\"\n",
    "\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            num_retries = 0\n",
    "            delay = initial_delay\n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "\n",
    "                except errors as e:\n",
    "                    num_retries += 1\n",
    "                    if num_retries > max_retries:\n",
    "                        raise Exception(\n",
    "                            f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
    "                        )\n",
    "                    delay = min(\n",
    "                        delay\n",
    "                        * exponential_base\n",
    "                        * (1 + jitter * random.random()),  # nosec\n",
    "                        max_wait,\n",
    "                    )\n",
    "                    logging.info(\n",
    "                        f\"Note: OpenAI's API rate limit reached. Command will automatically retry in {int(delay)} seconds. For more information visit: https://help.openai.com/en/articles/5955598-is-api-usage-subject-to-any-rate-limits\",\n",
    "                    )\n",
    "                    time.sleep(delay)\n",
    "\n",
    "                except Exception as e:\n",
    "                    raise e\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return decorator\n",
    "\n",
    "\n",
    "@_retry_with_exponential_backoff()\n",
    "def _completions_with_backoff(*args, **kwargs):\n",
    "    return openai.ChatCompletion.create(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaf46de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "SYSTEM_INSTRUCTION = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"Your name is Fastkafka AI, an advanced chatbot specialized in Fastkafka. Your primary goal is to assist users to the best of your ability. \n",
    "\"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff34f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # | export\n",
    "\n",
    "# FEW_SHOT_EXAMPLES = [\n",
    "#     {\n",
    "#         \"role\": \"system\",\n",
    "#         \"name\":\"example_user\",\n",
    "#         \"content\": \"how to optimise google ads?\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"role\": \"system\",\n",
    "#         \"name\": \"example_assistant\",\n",
    "#         \"content\": \"\"\"If you're curious, we'd love to show you more! Log in now by clicking the button below and\n",
    "# discover all the fascinating details. ###show_login_btn###\"\"\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"role\": \"system\",\n",
    "#         \"name\":\"example_user\",\n",
    "#         \"content\": \"tallest mountain in the world?\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"role\": \"system\",\n",
    "#         \"name\": \"example_assistant\",\n",
    "#         \"content\": \"\"\"Unfortunately, I am only capable of providing information related to Google Ads campaigns and their optimization.\n",
    "#  Is there a specific question or problem you need help with regarding Google Ads? Please let me know, and I'll do my best to help.\"\"\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"role\": \"system\",\n",
    "#         \"name\":\"example_user\",\n",
    "#         \"content\": \"can you please tell me a joke?\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"role\": \"system\",\n",
    "#         \"name\": \"example_assistant\",\n",
    "#         \"content\": \"\"\"Unfortunately, I am only capable of providing information related to Google Ads campaigns and their optimization.\n",
    "#  Is there a specific question or problem you need help with regarding Google Ads? Please let me know, and I'll do my best to help.\"\"\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"role\": \"system\",\n",
    "#         \"name\":\"example_user\",\n",
    "#         \"content\": \"Great job so far, these have been perfect\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"role\": \"system\",\n",
    "#         \"name\": \"example_assistant\",\n",
    "#         \"content\": \"\"\"Thank you! I'm glad I could assist you. If you have any more questions or need further \n",
    "# assistance, feel free to ask.\"\"\",\n",
    "#     },\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c873deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "DEFAULT_MESSAGE_TEMPLATE = [SYSTEM_INSTRUCTION] #+ FEW_SHOT_EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bdc1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'Your name is Fastkafka AI, an advanced chatbot specialized in Fastkafka. Your primary goal is to assist users to the best of your ability. \\n'}]\n"
     ]
    }
   ],
   "source": [
    "print(DEFAULT_MESSAGE_TEMPLATE)\n",
    "assert DEFAULT_MESSAGE_TEMPLATE[0] == SYSTEM_INSTRUCTION\n",
    "# assert DEFAULT_MESSAGE_TEMPLATE[1:] == FEW_SHOT_EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4446d8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"A computer is an electronic device that can perform various operations on data, such as storing, retrieving, and processing information. It can execute instructions and perform calculations at a high speed, making it a powerful tool for a wide range of applications. Computers come in different forms, including desktops, laptops, tablets, and smartphones, and they are used in various fields, such as education, business, entertainment, and research.\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = DEFAULT_MESSAGE_TEMPLATE + [{\"role\": \"user\", \"content\": \"What is a computer?\"}]\n",
    "response = _completions_with_backoff(\n",
    "    model= \"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf6f165",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def mock_openai_create():\n",
    "    mock_choices = {\"choices\": [{\"message\": {\"content\": \"This is a mock response\"}}]}\n",
    "\n",
    "    with unittest.mock.patch(\"openai.ChatCompletion\") as mock:\n",
    "        mock.create.return_value = mock_choices\n",
    "        yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b42245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a mock response\n"
     ]
    }
   ],
   "source": [
    "with mock_openai_create():\n",
    "    response = openai.ChatCompletion.create()\n",
    "    ret_val = response['choices'][0]['message']['content']\n",
    "    print(ret_val)\n",
    "    assert ret_val == \"This is a mock response\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b4691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of retries (1) exceeded.\n"
     ]
    }
   ],
   "source": [
    "@_retry_with_exponential_backoff()\n",
    "def mock_func():\n",
    "    return \"Success\"\n",
    "\n",
    "\n",
    "assert mock_func() == \"Success\"\n",
    "\n",
    "\n",
    "# Test max retries exceeded\n",
    "@_retry_with_exponential_backoff(max_retries=1)\n",
    "def mock_func_error():\n",
    "    raise openai.error.RateLimitError\n",
    "\n",
    "\n",
    "with pytest.raises(Exception) as e:\n",
    "    mock_func_error()\n",
    "\n",
    "print(e.value)\n",
    "assert str(e.value) == \"Maximum number of retries (1) exceeded.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7326f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "router = APIRouter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "class GenerateChatRequest(BaseModel):\n",
    "    message_history: List[Dict[str, str]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9296f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@router.post(\"/\")\n",
    "def generate_chat_response(\n",
    "    generate_chat_response_request: GenerateChatRequest,\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"Generate a chat response.\n",
    "\n",
    "    Args:\n",
    "        generate_chat_response_request: A GenerateChatRequest object.\n",
    "\n",
    "    Returns:\n",
    "        The response generated by Open Ai's text-davinci-003 model\n",
    "\n",
    "    !!! note\n",
    "\n",
    "        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n",
    "    \"\"\"\n",
    "    messages = DEFAULT_MESSAGE_TEMPLATE + generate_chat_response_request.message_history\n",
    "    response = _completions_with_backoff(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    ret_val = {\"message\": response['choices'][0]['message']['content']}\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4619c973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'This is a mock response'}\n"
     ]
    }
   ],
   "source": [
    "with mock_openai_create():\n",
    "    message_history = [\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"How can I help you\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"What is your name?\"},\n",
    "    ]\n",
    "    generate_chat_response_request = GenerateChatRequest(\n",
    "        message_history=message_history\n",
    "    )\n",
    "    actual = generate_chat_response(generate_chat_response_request)\n",
    "    print(actual)\n",
    "    assert actual == {\"message\": \"This is a mock response\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb4767f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
